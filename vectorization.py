# -*- coding: utf-8 -*-
"""vectorization.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16DSE48vFfXN7kUJxPjF9JR-oj6hLLWNi
"""

from sklearn.feature_extraction.text import TfidfVectorizer

from gensim.models import Word2Vec
from nltk.tokenize import word_tokenize

def vectorize_documents(documents):
    tokenized_docs = [word_tokenize(documents) for doc in documents]
    word2vec_model = Word2Vec(sentences=tokenized_docs, vector_size=100, window=5, min_count=2, workers=4)
    print(word2vec_model.wv['space'])

def TfidfVectorizer(documents):
  vectorizer = TfidfVectorizer(max_features=5000)
  X_tfidf = vectorizer.fit_transform(documents)